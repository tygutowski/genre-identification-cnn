\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

\lstset{language=Python,
        basicstyle=\ttfamily\small,
        keywordstyle=\color{blue},
        stringstyle=\color{red},
        commentstyle=\color{green},
        morecomment=[l][\color{magenta}]{\#}
}

\title{Music Genres Classification Derived from Album Cover Using Convolutional Neural Networks}
\author{Tyler Gutowski}
\date{\today}

\begin{document}

\maketitle

\section{Introduction}
Music genres are a reflection of artistic, cultural, and historical elements, and the visual designs of album covers are indicative of these genres. This project explores the classification of music genres using visual cues from album covers through the use of Convolutional Neural Networks (CNNs). We hypothesize that CNNs can effectively classify album art into music genres, offering insights into the relationship between visual art and music.

\section{Data Preparation}
\subsection{Data Collection}
The artist data, album data, and album cover images were initially collected using the Spotify API. The dataset was constructed containing paths to album images and their corresponding genre labels, finding the album data through the metadata provided by Spotify. Unfortunately, albums don't have specific genres while artists do, which meant that for each album requested, an artist request must be sent as well, doubling the number of Spotify API calls. Due to the large number of images needed for the training of the network, it was decided that APIs were not the best method. Instead, the MusicOSet dataset was used, which provides information for 26,522 albums and 11,518 artists stored in .csv files. The .csv files contained links to images, so no API calls were necessary.

\subsection{Data Preprocessing}
A script was written to download every single image from the URLs in the csv files. It is standard practice to separate classification into unique folders, but because some albums consisted of multiple genres, all of the albums were stored in a single folder. Artists such as Joey Bada\$\$ had multiple genres, such as conscious hip hop, gangster rap, hip hop, pop rap, rap, southern hip hop, trap music, and underground hip hop. There were a total of 1378 unique genres, which is far too many to train, especially with a miniature version of ResNet.

To condense the genres down, only the top 2.5\% of genres were kept, which left 24 genres. Unfortunately, because specific genres were so oversaturated, six of the top genres were rock, contemporary rock, hard rock, soft rock, pop rock, and country rock. Although these genres are separate, it is difficult to generalize data about these albums, so they were condensed into a single rock genre.

After condensing the genres further, we were left with three categories of rock, hip hop, and country. These genres were manually chosen because each genre has relatively unique album art. The album art of country music typically consists of a white man in a hat, which helps the model recognize patterns like this. (REDLINING PAPER)

The unique genres were then only kept. If an album contained both rock and country, it was dropped. If an album contained rock and alternative rock, it was categorized as rock. This left the genres with approximately 7000 rock albums, 1400 hip hop albums, and 1200 country albums. Training the model on this data would heavily skew the model to favor rock albums, so the training data was pruned to have 1200 of each genre.

Finally, album cover images were resized to a standard dimension of 128 by 128 pixels, with 3 channels (RGB). 

\section{Methodology}
\subsection{Model Architecture}
The architecture of the CNN was critical to the project's success. The model consisted of multiple layers, each designed to capture different aspects of the image data. The Conv2D layers were responsible for extracting features from the images, while the MaxPooling2D layers reduced the dimensionality of these features. The Flatten layer converted the 2D features into a 1D vector, which was then processed through Dense layers for classification. Dropout layers were included to prevent overfitting.

\subsection{Training Process}
The model's training involved several steps. Firstly, the preprocessed dataset was loaded into the model. The genre labels were one-hot encoded to facilitate classification. The dataset was then split into training and testing sets. The model was compiled with a categorical cross-entropy loss function and optimized using the Adam optimizer. The training process was monitored for accuracy and loss metrics to ensure effective learning.

\section{Results and Discussion}
\subsection{Model Evaluation}
The model's performance was evaluated using the testing set. The evaluation focused on accuracy and loss metrics, providing a quantitative measure of the model's effectiveness. A confusion matrix was generated to visualize the model's performance across different genres.

\subsection{Visualization}
Visualization tools were used to illustrate the model's classification accuracy per genre. The confusion matrix provided insights into the genres that were most accurately classified and those that posed challenges.

\section{Conclusion}
This research demonstrates the potential of using visual cues from album covers for music genre classification. The CNN model showed promising results, indicating that album cover imagery contains significant information relevant to genre classification. This study opens avenues for further research in the field of music classification, particularly in exploring the relationship between audio and visual data in understanding music genres.

REDLINING In Country Music
Dr. Jada E. Watson
https://songdata.ca/wp-content/uploads/2021/03/SongData-Watson-Redlining-Country-Music-032021.pdf



\end{document}

